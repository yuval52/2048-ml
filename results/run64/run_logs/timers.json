{
    "name": "root",
    "gauges": {
        "Player.Policy.Entropy.mean": {
            "value": 0.2627779245376587,
            "min": 0.02993548847734928,
            "max": 0.2627779245376587,
            "count": 5
        },
        "Player.Policy.Entropy.sum": {
            "value": 2624.888671875,
            "min": 302.5879211425781,
            "max": 2624.888671875,
            "count": 5
        },
        "Player.Step.mean": {
            "value": 49985.0,
            "min": 9891.0,
            "max": 49985.0,
            "count": 5
        },
        "Player.Step.sum": {
            "value": 49985.0,
            "min": 9891.0,
            "max": 49985.0,
            "count": 5
        },
        "Player.Policy.ExtrinsicValueEstimate.mean": {
            "value": 705262848.0,
            "min": 634643520.0,
            "max": 859843008.0,
            "count": 5
        },
        "Player.Policy.ExtrinsicValueEstimate.sum": {
            "value": 220042002432.0,
            "min": 72984002560.0,
            "max": 220042002432.0,
            "count": 5
        },
        "Player.Environment.EpisodeLength.mean": {
            "value": 32.06209150326797,
            "min": 32.06209150326797,
            "max": 182.16666666666666,
            "count": 5
        },
        "Player.Environment.EpisodeLength.sum": {
            "value": 9811.0,
            "min": 9811.0,
            "max": 10011.0,
            "count": 5
        },
        "Player.Environment.CumulativeReward.mean": {
            "value": 89.02622847537525,
            "min": 89.02622847537525,
            "max": 1250.851851851852,
            "count": 5
        },
        "Player.Environment.CumulativeReward.sum": {
            "value": 27152.999684989452,
            "min": 27152.999684989452,
            "max": 67546.0,
            "count": 5
        },
        "Player.Policy.ExtrinsicReward.mean": {
            "value": 89.02622847537525,
            "min": 89.02622847537525,
            "max": 1250.851851851852,
            "count": 5
        },
        "Player.Policy.ExtrinsicReward.sum": {
            "value": 27152.999684989452,
            "min": 27152.999684989452,
            "max": 67546.0,
            "count": 5
        },
        "Player.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 5
        },
        "Player.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 5
        },
        "Player.Losses.PolicyLoss.mean": {
            "value": 0.11063585021474864,
            "min": 0.07519753062806558,
            "max": 0.11063585021474864,
            "count": 2
        },
        "Player.Losses.PolicyLoss.sum": {
            "value": 0.11063585021474864,
            "min": 0.07519753062806558,
            "max": 0.11063585021474864,
            "count": 2
        },
        "Player.Losses.ValueLoss.mean": {
            "value": 1.8469846562268776e+16,
            "min": 1.8469846562268776e+16,
            "max": 3.675831443432407e+16,
            "count": 2
        },
        "Player.Losses.ValueLoss.sum": {
            "value": 1.8469846562268776e+16,
            "min": 1.8469846562268776e+16,
            "max": 3.675831443432407e+16,
            "count": 2
        },
        "Player.Policy.LearningRate.mean": {
            "value": 0.00010000000000000002,
            "min": 0.00010000000000000002,
            "max": 0.00010000000000000002,
            "count": 2
        },
        "Player.Policy.LearningRate.sum": {
            "value": 0.00010000000000000002,
            "min": 0.00010000000000000002,
            "max": 0.00010000000000000002,
            "count": 2
        },
        "Player.Policy.Epsilon.mean": {
            "value": 0.09999999999999999,
            "min": 0.09999999999999999,
            "max": 0.09999999999999999,
            "count": 2
        },
        "Player.Policy.Epsilon.sum": {
            "value": 0.09999999999999999,
            "min": 0.09999999999999999,
            "max": 0.09999999999999999,
            "count": 2
        },
        "Player.Policy.Beta.mean": {
            "value": 0.00010000000000000002,
            "min": 0.00010000000000000002,
            "max": 0.00010000000000000002,
            "count": 2
        },
        "Player.Policy.Beta.sum": {
            "value": 0.00010000000000000002,
            "min": 0.00010000000000000002,
            "max": 0.00010000000000000002,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1744758526",
        "python_version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Yuval\\Unity Projects\\2048-ml\\venv\\Scripts\\mlagents-learn config\\Player.yaml --run-id=run64",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1744759215"
    },
    "total": 689.1306749000069,
    "count": 1,
    "self": 0.004620300009264611,
    "children": {
        "run_training.setup": {
            "total": 0.08466249999764841,
            "count": 1,
            "self": 0.08466249999764841
        },
        "TrainerController.start_learning": {
            "total": 689.0413920999999,
            "count": 1,
            "self": 0.9864412019815063,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.926041700004134,
                    "count": 1,
                    "self": 7.926041700004134
                },
                "TrainerController.advance": {
                    "total": 679.960178098001,
                    "count": 51058,
                    "self": 0.8810350978601491,
                    "children": {
                        "env_step": {
                            "total": 660.5531822001212,
                            "count": 51058,
                            "self": 464.51826459905715,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 195.3277480003744,
                                    "count": 51059,
                                    "self": 2.552945700706914,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 192.7748022996675,
                                            "count": 51059,
                                            "self": 192.7748022996675
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.7071696006896673,
                                    "count": 51057,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 609.5741704988177,
                                            "count": 51057,
                                            "is_parallel": true,
                                            "self": 260.7985024976806,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.000414699999964796,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0002275000006193295,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0001871999993454665,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0001871999993454665
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 348.7752533011371,
                                                    "count": 51057,
                                                    "is_parallel": true,
                                                    "self": 4.041065700148465,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 3.2190752005699323,
                                                            "count": 51057,
                                                            "is_parallel": true,
                                                            "self": 3.2190752005699323
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 329.0349768994638,
                                                            "count": 51057,
                                                            "is_parallel": true,
                                                            "self": 329.0349768994638
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 12.48013550095493,
                                                            "count": 51057,
                                                            "is_parallel": true,
                                                            "self": 7.241562501178123,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 5.238572999776807,
                                                                    "count": 102114,
                                                                    "is_parallel": true,
                                                                    "self": 5.238572999776807
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 18.525960800019675,
                            "count": 51057,
                            "self": 1.4616017012740485,
                            "children": {
                                "process_trajectory": {
                                    "total": 4.593062198735424,
                                    "count": 51057,
                                    "self": 4.593062198735424
                                },
                                "_update_policy": {
                                    "total": 12.471296900010202,
                                    "count": 2,
                                    "self": 4.662311699910788,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 7.808985200099414,
                                            "count": 640,
                                            "self": 7.808985200099414
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.00000761449337e-06,
                    "count": 1,
                    "self": 1.00000761449337e-06
                },
                "TrainerController._save_models": {
                    "total": 0.16873010000563227,
                    "count": 1,
                    "self": 0.012637899999390356,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.1560922000062419,
                            "count": 1,
                            "self": 0.1560922000062419
                        }
                    }
                }
            }
        }
    }
}